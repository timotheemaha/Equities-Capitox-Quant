{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deb2979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.66-py2.py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\tushar\\documents\\github\\equities-capitox-quant\\.venv\\lib\\site-packages (from yfinance) (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\tushar\\documents\\github\\equities-capitox-quant\\.venv\\lib\\site-packages (from yfinance) (2.3.5)\n",
      "Collecting requests>=2.31 (from yfinance)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.12.tar.gz (19 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\tushar\\documents\\github\\equities-capitox-quant\\.venv\\lib\\site-packages (from yfinance) (4.5.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\tushar\\documents\\github\\equities-capitox-quant\\.venv\\lib\\site-packages (from yfinance) (2025.2)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Downloading frozendict-2.4.7-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.18.3.tar.gz (3.0 MB)\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "     ------------------------ --------------- 1.8/3.0 MB 9.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.0/3.0 MB 8.6 MB/s  0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting beautifulsoup4>=4.11.1 (from yfinance)\n",
      "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting curl_cffi>=0.7 (from yfinance)\n",
      "  Downloading curl_cffi-0.13.0-cp39-abi3-win_amd64.whl.metadata (13 kB)\n",
      "Collecting protobuf>=3.19.0 (from yfinance)\n",
      "  Downloading protobuf-6.33.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting websockets>=13.0 (from yfinance)\n",
      "  Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4>=4.11.1->yfinance)\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from beautifulsoup4>=4.11.1->yfinance)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting cffi>=1.12.0 (from curl_cffi>=0.7->yfinance)\n",
      "  Downloading cffi-2.0.0-cp313-cp313-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting certifi>=2024.2.2 (from curl_cffi>=0.7->yfinance)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pycparser (from cffi>=1.12.0->curl_cffi>=0.7->yfinance)\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tushar\\documents\\github\\equities-capitox-quant\\.venv\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tushar\\documents\\github\\equities-capitox-quant\\.venv\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tushar\\documents\\github\\equities-capitox-quant\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.31->yfinance)\n",
      "  Downloading charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.31->yfinance)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31->yfinance)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Downloading yfinance-0.2.66-py2.py3-none-any.whl (123 kB)\n",
      "Downloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
      "Downloading curl_cffi-0.13.0-cp39-abi3-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 8.3 MB/s  0:00:00\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Downloading cffi-2.0.0-cp313-cp313-win_amd64.whl (183 kB)\n",
      "Downloading frozendict-2.4.7-py3-none-any.whl (16 kB)\n",
      "Downloading protobuf-6.33.1-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl (176 kB)\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Building wheels for collected packages: multitasking, peewee\n",
      "  Building wheel for multitasking (pyproject.toml): started\n",
      "  Building wheel for multitasking (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for multitasking: filename=multitasking-0.0.12-py3-none-any.whl size=15703 sha256=5242e20ebe39fd2a2dccd75f9247917fb280c4cbd33875d4329dfde32803b3a5\n",
      "  Stored in directory: c:\\users\\tushar\\appdata\\local\\pip\\cache\\wheels\\1e\\df\\0f\\e2bbb22d689b30c681feb5410ab64a2523437b34c8ecfc6476\n",
      "  Building wheel for peewee (pyproject.toml): started\n",
      "  Building wheel for peewee (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for peewee: filename=peewee-3.18.3-py3-none-any.whl size=139181 sha256=8b04cf74be4e988463d38817ad74a4daf7e4ae87f193d7f0f1d0a15d2cfbaeac\n",
      "  Stored in directory: c:\\users\\tushar\\appdata\\local\\pip\\cache\\wheels\\8c\\a9\\a4\\df972cd49f865ffde174d9c5b26f14f08f8a363ed31e10ff91\n",
      "Successfully built multitasking peewee\n",
      "Installing collected packages: peewee, multitasking, websockets, urllib3, typing-extensions, soupsieve, pycparser, protobuf, idna, frozendict, charset_normalizer, certifi, requests, cffi, beautifulsoup4, curl_cffi, yfinance\n",
      "\n",
      "   ----------------------------------------  0/17 [peewee]\n",
      "   ----------------------------------------  0/17 [peewee]\n",
      "   ----------------------------------------  0/17 [peewee]\n",
      "   ----------------------------------------  0/17 [peewee]\n",
      "   ----------------------------------------  0/17 [peewee]\n",
      "   ----------------------------------------  0/17 [peewee]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ---- -----------------------------------  2/17 [websockets]\n",
      "   ------- --------------------------------  3/17 [urllib3]\n",
      "   ------- --------------------------------  3/17 [urllib3]\n",
      "   ------- --------------------------------  3/17 [urllib3]\n",
      "   ------- --------------------------------  3/17 [urllib3]\n",
      "   ------- --------------------------------  3/17 [urllib3]\n",
      "   ------- --------------------------------  3/17 [urllib3]\n",
      "   ------- --------------------------------  3/17 [urllib3]\n",
      "   ------- --------------------------------  3/17 [urllib3]\n",
      "   ------- --------------------------------  3/17 [urllib3]\n",
      "   ------- --------------------------------  3/17 [urllib3]\n",
      "   ------- --------------------------------  3/17 [urllib3]\n",
      "   ------- --------------------------------  3/17 [urllib3]\n",
      "   ------- --------------------------------  3/17 [urllib3]\n",
      "   --------- ------------------------------  4/17 [typing-extensions]\n",
      "   ----------- ----------------------------  5/17 [soupsieve]\n",
      "   ----------- ----------------------------  5/17 [soupsieve]\n",
      "   -------------- -------------------------  6/17 [pycparser]\n",
      "   -------------- -------------------------  6/17 [pycparser]\n",
      "   -------------- -------------------------  6/17 [pycparser]\n",
      "   -------------- -------------------------  6/17 [pycparser]\n",
      "   -------------- -------------------------  6/17 [pycparser]\n",
      "   -------------- -------------------------  6/17 [pycparser]\n",
      "   -------------- -------------------------  6/17 [pycparser]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ---------------- -----------------------  7/17 [protobuf]\n",
      "   ------------------ ---------------------  8/17 [idna]\n",
      "   ------------------ ---------------------  8/17 [idna]\n",
      "   ------------------ ---------------------  8/17 [idna]\n",
      "   --------------------- ------------------  9/17 [frozendict]\n",
      "   --------------------- ------------------  9/17 [frozendict]\n",
      "   ----------------------- ---------------- 10/17 [charset_normalizer]\n",
      "   ----------------------- ---------------- 10/17 [charset_normalizer]\n",
      "   ----------------------- ---------------- 10/17 [charset_normalizer]\n",
      "   ----------------------- ---------------- 10/17 [charset_normalizer]\n",
      "   ----------------------- ---------------- 10/17 [charset_normalizer]\n",
      "   ------------------------- -------------- 11/17 [certifi]\n",
      "   ---------------------------- ----------- 12/17 [requests]\n",
      "   ---------------------------- ----------- 12/17 [requests]\n",
      "   ---------------------------- ----------- 12/17 [requests]\n",
      "   ---------------------------- ----------- 12/17 [requests]\n",
      "   ---------------------------- ----------- 12/17 [requests]\n",
      "   ------------------------------ --------- 13/17 [cffi]\n",
      "   ------------------------------ --------- 13/17 [cffi]\n",
      "   ------------------------------ --------- 13/17 [cffi]\n",
      "   ------------------------------ --------- 13/17 [cffi]\n",
      "   ------------------------------ --------- 13/17 [cffi]\n",
      "   -------------------------------- ------- 14/17 [beautifulsoup4]\n",
      "   -------------------------------- ------- 14/17 [beautifulsoup4]\n",
      "   -------------------------------- ------- 14/17 [beautifulsoup4]\n",
      "   -------------------------------- ------- 14/17 [beautifulsoup4]\n",
      "   ----------------------------------- ---- 15/17 [curl_cffi]\n",
      "   ----------------------------------- ---- 15/17 [curl_cffi]\n",
      "   ----------------------------------- ---- 15/17 [curl_cffi]\n",
      "   ----------------------------------- ---- 15/17 [curl_cffi]\n",
      "   ----------------------------------- ---- 15/17 [curl_cffi]\n",
      "   ------------------------------------- -- 16/17 [yfinance]\n",
      "   ------------------------------------- -- 16/17 [yfinance]\n",
      "   ------------------------------------- -- 16/17 [yfinance]\n",
      "   ------------------------------------- -- 16/17 [yfinance]\n",
      "   ------------------------------------- -- 16/17 [yfinance]\n",
      "   ------------------------------------- -- 16/17 [yfinance]\n",
      "   ------------------------------------- -- 16/17 [yfinance]\n",
      "   ------------------------------------- -- 16/17 [yfinance]\n",
      "   ------------------------------------- -- 16/17 [yfinance]\n",
      "   ------------------------------------- -- 16/17 [yfinance]\n",
      "   ------------------------------------- -- 16/17 [yfinance]\n",
      "   ------------------------------------- -- 16/17 [yfinance]\n",
      "   ------------------------------------- -- 16/17 [yfinance]\n",
      "   ------------------------------------- -- 16/17 [yfinance]\n",
      "   ---------------------------------------- 17/17 [yfinance]\n",
      "\n",
      "Successfully installed beautifulsoup4-4.14.2 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 curl_cffi-0.13.0 frozendict-2.4.7 idna-3.11 multitasking-0.0.12 peewee-3.18.3 protobuf-6.33.1 pycparser-2.23 requests-2.32.5 soupsieve-2.8 typing-extensions-4.15.0 urllib3-2.5.0 websockets-15.0.1 yfinance-0.2.66\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance requests pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9c5e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "959139c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request Status Code: 200\n",
      "\n",
      "Success! Found the table with id='constituents'.\n",
      "Total tickers: 503\n",
      "['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A', 'APD', 'ABNB', 'AKAM', 'ALB', 'ARE', 'ALGN', 'ALLE', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AMCR', 'AEE', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'AME', 'AMGN', 'APH', 'ADI', 'AON', 'APA', 'APO', 'AAPL', 'AMAT', 'APP', 'APTV', 'ACGL', 'ADM', 'ANET', 'AJG', 'AIZ', 'T', 'ATO', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'AXON', 'BKR', 'BALL', 'BAC', 'BAX', 'BDX', 'BRK-B', 'BBY', 'TECH', 'BIIB', 'BLK', 'BX', 'XYZ', 'BK', 'BA', 'BKNG', 'BSX', 'BMY', 'AVGO', 'BR', 'BRO', 'BF-B', 'BLDR', 'BG', 'BXP', 'CHRW', 'CDNS', 'CPT', 'CPB', 'COF', 'CAH', 'CCL', 'CARR', 'CAT', 'CBOE', 'CBRE', 'CDW', 'COR', 'CNC', 'CNP', 'CF', 'CRL', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CLX', 'CME', 'CMS', 'KO', 'CTSH', 'COIN', 'CL', 'CMCSA', 'CAG', 'COP', 'ED', 'STZ', 'CEG', 'COO', 'CPRT', 'GLW', 'CPAY', 'CTVA', 'CSGP', 'COST', 'CTRA', 'CRWD', 'CCI', 'CSX', 'CMI', 'CVS', 'DHR', 'DRI', 'DDOG', 'DVA', 'DAY', 'DECK', 'DE', 'DELL', 'DAL', 'DVN', 'DXCM', 'FANG', 'DLR', 'DG', 'DLTR', 'D', 'DPZ', 'DASH', 'DOV', 'DOW', 'DHI', 'DTE', 'DUK', 'DD', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'ELV', 'EME', 'EMR', 'ETR', 'EOG', 'EPAM', 'EQT', 'EFX', 'EQIX', 'EQR', 'ERIE', 'ESS', 'EL', 'EG', 'EVRG', 'ES', 'EXC', 'EXE', 'EXPE', 'EXPD', 'EXR', 'XOM', 'FFIV', 'FDS', 'FICO', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FSLR', 'FE', 'FISV', 'F', 'FTNT', 'FTV', 'FOXA', 'FOX', 'BEN', 'FCX', 'GRMN', 'IT', 'GE', 'GEHC', 'GEV', 'GEN', 'GNRC', 'GD', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GL', 'GDDY', 'GS', 'HAL', 'HIG', 'HAS', 'HCA', 'DOC', 'HSIC', 'HSY', 'HPE', 'HLT', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HWM', 'HPQ', 'HUBB', 'HUM', 'HBAN', 'HII', 'IBM', 'IEX', 'IDXX', 'ITW', 'INCY', 'IR', 'PODD', 'INTC', 'IBKR', 'ICE', 'IFF', 'IP', 'IPG', 'INTU', 'ISRG', 'IVZ', 'INVH', 'IQV', 'IRM', 'JBHT', 'JBL', 'JKHY', 'J', 'JNJ', 'JCI', 'JPM', 'K', 'KVUE', 'KDP', 'KEY', 'KEYS', 'KMB', 'KIM', 'KMI', 'KKR', 'KLAC', 'KHC', 'KR', 'LHX', 'LH', 'LRCX', 'LW', 'LVS', 'LDOS', 'LEN', 'LII', 'LLY', 'LIN', 'LYV', 'LKQ', 'LMT', 'L', 'LOW', 'LULU', 'LYB', 'MTB', 'MPC', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MTCH', 'MKC', 'MCD', 'MCK', 'MDT', 'MRK', 'META', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MRNA', 'MHK', 'MOH', 'TAP', 'MDLZ', 'MPWR', 'MNST', 'MCO', 'MS', 'MOS', 'MSI', 'MSCI', 'NDAQ', 'NTAP', 'NFLX', 'NEM', 'NWSA', 'NWS', 'NEE', 'NKE', 'NI', 'NDSN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'NVR', 'NXPI', 'ORLY', 'OXY', 'ODFL', 'OMC', 'ON', 'OKE', 'ORCL', 'OTIS', 'PCAR', 'PKG', 'PLTR', 'PANW', 'PSKY', 'PH', 'PAYX', 'PAYC', 'PYPL', 'PNR', 'PEP', 'PFE', 'PCG', 'PM', 'PSX', 'PNW', 'PNC', 'POOL', 'PPG', 'PPL', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PTC', 'PSA', 'PHM', 'PWR', 'QCOM', 'DGX', 'Q', 'RL', 'RJF', 'RTX', 'O', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RVTY', 'HOOD', 'ROK', 'ROL', 'ROP', 'ROST', 'RCL', 'SPGI', 'CRM', 'SBAC', 'SLB', 'STX', 'SRE', 'NOW', 'SHW', 'SPG', 'SWKS', 'SJM', 'SW', 'SNA', 'SOLS', 'SOLV', 'SO', 'LUV', 'SWK', 'SBUX', 'STT', 'STLD', 'STE', 'SYK', 'SMCI', 'SYF', 'SNPS', 'SYY', 'TMUS', 'TROW', 'TTWO', 'TPR', 'TRGP', 'TGT', 'TEL', 'TDY', 'TER', 'TSLA', 'TXN', 'TPL', 'TXT', 'TMO', 'TJX', 'TKO', 'TTD', 'TSCO', 'TT', 'TDG', 'TRV', 'TRMB', 'TFC', 'TYL', 'TSN', 'USB', 'UBER', 'UDR', 'ULTA', 'UNP', 'UAL', 'UPS', 'URI', 'UNH', 'UHS', 'VLO', 'VTR', 'VLTO', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VTRS', 'VICI', 'V', 'VST', 'VMC', 'WRB', 'GWW', 'WAB', 'WMT', 'DIS', 'WBD', 'WM', 'WAT', 'WEC', 'WFC', 'WELL', 'WST', 'WDC', 'WY', 'WSM', 'WMB', 'WTW', 'WDAY', 'WYNN', 'XEL', 'XYL', 'YUM', 'ZBRA', 'ZBH', 'ZTS']\n"
     ]
    }
   ],
   "source": [
    "# Scrape Wikipedia for S&P 500 tickers\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "\n",
    "# Pretend to be a common browser\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Fetch the page *with the headers*\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# --- DIAGNOSTIC CHECK ---\n",
    "# Check if the request was successful (should be 200)\n",
    "print(f\"Request Status Code: {response.status_code}\")\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "table = soup.find('table', {'id': 'constituents'})\n",
    "if table:\n",
    "    print(\"\\nSuccess! Found the table with id='constituents'.\")\n",
    "    ticker_list = []\n",
    "    \n",
    "    # Get all rows from the table body, skip the header row [1:]\n",
    "    for row in table.find('tbody').find_all('tr')[1:]: \n",
    "        \n",
    "        # Get all data cells ('td') in the row\n",
    "        cols = row.find_all('td')\n",
    "        \n",
    "        if cols:\n",
    "            # The ticker is the text in the very first cell (index 0)\n",
    "            ticker = cols[0].text.strip()\n",
    "            ticker_list.append(ticker)\n",
    "\n",
    "    print(f\"Total tickers: {len(ticker_list)}\")\n",
    "    # Change \".\" to \"-\". This is because the Wikipedia list uses \"BRK.B\" but yfinance uses \"BRK-B\"\n",
    "    ticker_list = [ticker.replace('.', '-') for ticker in ticker_list]\n",
    "    print(ticker_list)\n",
    "else:\n",
    "    print(\"\\nError: Could not find table with id='constituents' even with headers.\")\n",
    "    print(\"This is strange, the page structure may have changed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46521eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading price history...\n",
      "Attempting to download 503 tickers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  503 of 503 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching sector data (this may take a moment)...\n",
      "Processed 50/501 tickers...\n",
      "Processed 100/501 tickers...\n",
      "Processed 150/501 tickers...\n",
      "Processed 200/501 tickers...\n",
      "Processed 250/501 tickers...\n",
      "Processed 300/501 tickers...\n",
      "Processed 350/501 tickers...\n",
      "Processed 400/501 tickers...\n",
      "Processed 450/501 tickers...\n",
      "Processed 500/501 tickers...\n",
      "MOMENTUM QUINTILE DISTRIBUTION\n",
      "\n",
      "Quintile Distribution:\n",
      "Momentum_Quintile\n",
      "1    4797\n",
      "2    4756\n",
      "3    4756\n",
      "4    4762\n",
      "5    4770\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of data with quintiles:\n",
      "         Date Ticker  Z_Momentum Momentum_Quintile\n",
      "0  2021-12-01      A    0.476937                 4\n",
      "1  2021-12-01   AAPL   -0.522009                 2\n",
      "2  2021-12-01   ABBV   -0.553359                 2\n",
      "3  2021-12-01    ABT   -0.178019                 3\n",
      "4  2021-12-01   ACGL   -1.023025                 1\n",
      "5  2021-12-01    ACN    0.622715                 4\n",
      "6  2021-12-01   ADBE    0.232228                 4\n",
      "7  2021-12-01    ADI   -0.247794                 3\n",
      "8  2021-12-01    ADM    1.399820                 5\n",
      "9  2021-12-01    ADP    0.227898                 3\n",
      "10 2021-12-01   ADSK   -0.949008                 2\n",
      "11 2021-12-01    AEE    0.282467                 4\n",
      "12 2021-12-01    AEP   -0.432514                 2\n",
      "13 2021-12-01    AES    0.062704                 3\n",
      "14 2021-12-01    AFL   -0.669961                 2\n",
      "15 2021-12-01    AIG    1.207860                 5\n",
      "16 2021-12-01    AIZ   -0.817869                 2\n",
      "17 2021-12-01    AJG    0.061086                 3\n",
      "18 2021-12-01   AKAM   -1.111098                 1\n",
      "19 2021-12-01    ALB    1.439728                 5\n",
      "MOMENTUM STRATEGY BACKTEST - Monthly Rebalancing\n",
      "\n",
      "Average Returns by Momentum Quintile (%):\n",
      "                   Mean_Monthly_Return  Median_Monthly_Return    Std_Dev  \\\n",
      "Momentum_Quintile                                                          \n",
      "1                             0.913031               0.534720  10.565001   \n",
      "2                             0.774204               0.607326   8.620509   \n",
      "3                             0.667367               0.653691   8.000618   \n",
      "4                             0.726253               0.418319   8.451497   \n",
      "5                             1.180971               0.703852  10.374100   \n",
      "\n",
      "                   Count  \n",
      "Momentum_Quintile         \n",
      "1                   4696  \n",
      "2                   4656  \n",
      "3                   4656  \n",
      "4                   4662  \n",
      "5                   4670  \n",
      "\n",
      "Momentum Spread (Q5 - Q1): 0.27% per month\n",
      "Annualized Spread: 3.22%\n",
      "Most Recent Momentum Z-Scores (Top 10):\n",
      "Ticker\n",
      "WELL    3.209991\n",
      "IDXX    2.685618\n",
      "HOOD    2.653515\n",
      "NRG     2.600566\n",
      "NEM     2.513194\n",
      "C       2.502096\n",
      "IBKR    2.337158\n",
      "GE      2.270260\n",
      "GEV     2.270260\n",
      "HWM     2.270260\n",
      "Name: 2025-11-01 00:00:00, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tushar\\AppData\\Local\\Temp\\ipykernel_6524\\487562654.py:153: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  quintile_stats = detailed_df.groupby('Momentum_Quintile')['Forward_Return'].agg([\n"
     ]
    }
   ],
   "source": [
    "def get_sector_map(tickers):\n",
    "    \"\"\"\n",
    "    Fetches sector information for a list of tickers.\n",
    "    Note: Fetching info one-by-one can be slow.\n",
    "    \"\"\"\n",
    "    sector_map = {}\n",
    "    print(\"Fetching sector data (this may take a moment)...\")\n",
    "    for i, ticker in enumerate(tickers, 1):\n",
    "        try:\n",
    "            # In a production environment, cache this data\n",
    "            info = yf.Ticker(ticker).info\n",
    "            sector_map[ticker] = info.get('sector', 'Unknown')\n",
    "            if i % 50 == 0:\n",
    "                print(f\"Processed {i}/{len(tickers)} tickers...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch sector for {ticker}: {e}\")\n",
    "            sector_map[ticker] = 'Unknown'\n",
    "    return sector_map\n",
    "\n",
    "def calculate_momentum_factor(tickers, lookback_years=5):\n",
    "    # 1. FETCH DATA\n",
    "    print(\"Downloading price history...\")\n",
    "    print(f\"Attempting to download {len(tickers)} tickers...\")\n",
    "    \n",
    "    try:\n",
    "        data = yf.download(\n",
    "            tickers, \n",
    "            period=f\"{lookback_years}y\", \n",
    "            interval=\"1mo\", \n",
    "            progress=True,\n",
    "            auto_adjust=True,\n",
    "            threads=True\n",
    "        )\n",
    "        \n",
    "        # When auto_adjust=True, yfinance returns adjusted prices directly\n",
    "        # For multiple tickers, columns are multi-level: (Price Type, Ticker)\n",
    "        # We need to extract just the Close prices\n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            # Multi-ticker case: select 'Close' from the multi-level columns\n",
    "            if 'Close' in data.columns.get_level_values(0):\n",
    "                data = data['Close']\n",
    "            else:\n",
    "                print(\"Available columns:\", data.columns.get_level_values(0).unique().tolist())\n",
    "                print(\"Error: Could not find 'Close' prices in data\")\n",
    "                return None, None, None\n",
    "        else:\n",
    "            # Single ticker or already the right format\n",
    "            if 'Close' in data.columns:\n",
    "                data = data['Close']\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading data: {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Drop columns with insufficient history (less than 12 months)\n",
    "    # We require > 12 non-NaN values\n",
    "    data = data.dropna(axis=1, thresh=12)\n",
    "    valid_tickers = data.columns.tolist()\n",
    "    \n",
    "    if len(valid_tickers) == 0:\n",
    "        print(\"ERROR: No valid tickers with sufficient data!\")\n",
    "        print(\"This may be due to network issues or yfinance rate limiting.\")\n",
    "        print(\"Try running the cell again or reduce the number of tickers.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # 2. CALCULATE RAW MOMENTUM\n",
    "    # Formula: P(t-2) / P(t-12) - 1\n",
    "    # logic: shift(2) moves the price from 2 months ago to current row\n",
    "    mom_raw = data.shift(2) / data.shift(12) - 1\n",
    "    \n",
    "    # Drop the first 12 months as they will be NaN due to the shift\n",
    "    mom_raw = mom_raw.dropna(how='all')\n",
    "\n",
    "    # 3. PREPARE FOR CROSS-SECTIONAL STANDARDIZATION\n",
    "    # Convert from Wide (Tickers as columns) to Long (Date/Ticker rows)\n",
    "    df_long = mom_raw.stack().reset_index()\n",
    "    df_long.columns = ['Date', 'Ticker', 'Raw_Momentum']\n",
    "    \n",
    "    # Map Sectors\n",
    "    sector_map = get_sector_map(valid_tickers)\n",
    "    df_long['Sector'] = df_long['Ticker'].map(sector_map)\n",
    "\n",
    "    # 4. WINSORIZATION (Cross-sectional per Date)\n",
    "    # We clip outliers at the 5th and 95th percentiles for each month\n",
    "    def winsorize_group(group):\n",
    "        lower = group.quantile(0.05)\n",
    "        upper = group.quantile(0.95)\n",
    "        return group.clip(lower, upper)\n",
    "\n",
    "    df_long['Mom_Winsorized'] = df_long.groupby('Date')['Raw_Momentum'] \\\n",
    "                                       .transform(winsorize_group)\n",
    "\n",
    "    # 5. SECTOR Z-SCORES\n",
    "    # Calculate Z-Score per Date and Sector\n",
    "    # Formula: (x - mean) / std\n",
    "    def calc_zscore(group):\n",
    "        if len(group) < 2: \n",
    "            return 0.0 # Neutral score if not enough peers in sector\n",
    "        sigma = group.std()\n",
    "        if sigma == 0:\n",
    "            return 0.0\n",
    "        return (group - group.mean()) / sigma\n",
    "\n",
    "    df_long['Z_Momentum'] = df_long.groupby(['Date', 'Sector'])['Mom_Winsorized'] \\\n",
    "                                   .transform(calc_zscore)\n",
    "    \n",
    "    # 6. ADD QUINTILES\n",
    "    # Group by date and assign quintiles (1 = lowest momentum, 5 = highest momentum)\n",
    "    df_long['Momentum_Quintile'] = df_long.groupby('Date')['Z_Momentum'].transform(\n",
    "        lambda x: pd.qcut(x, q=5, labels=[1, 2, 3, 4, 5], duplicates='drop')\n",
    "    )\n",
    "    \n",
    "    # 7. CALCULATE FORWARD RETURNS\n",
    "    # Convert price_data to long format\n",
    "    price_long = data.stack().reset_index()\n",
    "    price_long.columns = ['Date', 'Ticker', 'Price']\n",
    "    price_long = price_long.sort_values(['Ticker', 'Date'])\n",
    "    \n",
    "    # Calculate forward return: P(t+1)/P(t) - 1\n",
    "    price_long['Forward_Return'] = price_long.groupby('Ticker')['Price'].transform(\n",
    "        lambda x: x.shift(-1) / x - 1\n",
    "    )\n",
    "    \n",
    "    # Merge forward returns with detailed_df\n",
    "    df_long = df_long.merge(\n",
    "        price_long[['Date', 'Ticker', 'Forward_Return']],\n",
    "        on=['Date', 'Ticker'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Pivot back to wide format for easy viewing/trading matrix\n",
    "    final_factor = df_long.pivot(index='Date', columns='Ticker', values='Z_Momentum')\n",
    "    \n",
    "    return final_factor, df_long, data\n",
    "\n",
    "# --- EXECUTION ---\n",
    "\n",
    "# Run calculation\n",
    "z_score_matrix, detailed_df, price_data = calculate_momentum_factor(ticker_list)\n",
    "\n",
    "# Check if calculation was successful\n",
    "if z_score_matrix is not None and not z_score_matrix.empty:\n",
    "    # Display quintile distribution\n",
    "    print(\"MOMENTUM QUINTILE DISTRIBUTION\")\n",
    "    print(\"\\nQuintile Distribution:\")\n",
    "    print(detailed_df['Momentum_Quintile'].value_counts().sort_index())\n",
    "    print(f\"\\nSample of data with quintiles:\")\n",
    "    print(detailed_df[['Date', 'Ticker', 'Z_Momentum', 'Momentum_Quintile']].head(20))\n",
    "    \n",
    "    # Calculate backtest statistics\n",
    "    print(\"MOMENTUM STRATEGY BACKTEST - Monthly Rebalancing\")\n",
    "    \n",
    "    quintile_stats = detailed_df.groupby('Momentum_Quintile')['Forward_Return'].agg([\n",
    "        ('Mean_Monthly_Return', 'mean'),\n",
    "        ('Median_Monthly_Return', 'median'),\n",
    "        ('Std_Dev', 'std'),\n",
    "        ('Count', 'count')\n",
    "    ])\n",
    "    \n",
    "    # Convert to percentage\n",
    "    quintile_stats['Mean_Monthly_Return'] = quintile_stats['Mean_Monthly_Return'] * 100\n",
    "    quintile_stats['Median_Monthly_Return'] = quintile_stats['Median_Monthly_Return'] * 100\n",
    "    quintile_stats['Std_Dev'] = quintile_stats['Std_Dev'] * 100\n",
    "    \n",
    "    print(\"\\nAverage Returns by Momentum Quintile (%):\")\n",
    "    print(quintile_stats)\n",
    "    \n",
    "    # Calculate spread (Q5 - Q1)\n",
    "    if 5 in quintile_stats.index and 1 in quintile_stats.index:\n",
    "        spread = quintile_stats.loc[5, 'Mean_Monthly_Return'] - quintile_stats.loc[1, 'Mean_Monthly_Return']\n",
    "        print(f\"\\nMomentum Spread (Q5 - Q1): {spread:.2f}% per month\")\n",
    "        print(f\"Annualized Spread: {spread * 12:.2f}%\")\n",
    "    \n",
    "    # Output the most recent Momentum Z-Scores\n",
    "    print(\"Most Recent Momentum Z-Scores (Top 10):\")\n",
    "    latest_date = z_score_matrix.index[-1]\n",
    "    print(z_score_matrix.loc[latest_date].sort_values(ascending=False).head(10))\n",
    "else:\n",
    "    print(\"\\nCalculation failed. Please check the errors above and try again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65562e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running defensive factor calculation...\n",
      "\n",
      "Downloading daily price data for 503 tickers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[**********************70%*********              ]  350 of 503 completedFailed to get ticker 'ISRG' reason: Failed to perform, curl: (28) Operation timed out after 10003 milliseconds with 0 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.\n",
      "[*********************100%***********************]  503 of 503 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1256, 503)\n",
      "\n",
      "Calculating daily log returns...\n",
      "Calculating 60-day rolling realized volatility...\n",
      "Resampling to monthly frequency...\n",
      "Valid tickers with sufficient data: 501\n",
      "\n",
      "Mapping sectors from existing sector map...\n",
      "Applying winsorization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tushar\\AppData\\Local\\Temp\\ipykernel_6524\\3980232548.py:73: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_vol = annualized_vol.resample('M').last()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating sector-neutral Z-scores...\n",
      "\n",
      "======================================================================\n",
      "CALCULATION SUCCESSFUL\n",
      "======================================================================\n",
      "\n",
      "Data shape: (29353, 7)\n",
      "Date range: 2021-01-31 00:00:00 to 2025-11-30 00:00:00\n",
      "\n",
      "Most Recent Low Volatility Z-Scores (Top 10):\n",
      "Ticker\n",
      "DAY     1.748777\n",
      "JNJ     1.657850\n",
      "BR      1.629342\n",
      "TJX     1.550804\n",
      "MCD     1.550804\n",
      "MSFT    1.493270\n",
      "LIN     1.421507\n",
      "ADP     1.403932\n",
      "K       1.385116\n",
      "PG      1.385116\n",
      "Name: 2025-11-30 00:00:00, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def calculate_defensive_factor(tickers, sector_map, lookback_years=5, min_daily_obs=40):\n",
    "    \"\"\"\n",
    "    Calculate Low Volatility (Defensive) Factor\n",
    "    \n",
    "    Methodology:\n",
    "    1. Download daily price data\n",
    "    2. Calculate 60-day realized volatility using log returns\n",
    "    3. Annualize volatility: sqrt(252) * std(log returns over 60 days)\n",
    "    4. Invert volatility (lower vol = better): x_low = -sigma\n",
    "    5. Winsorize across stocks\n",
    "    6. Calculate sector-neutral Z-scores\n",
    "    \n",
    "    Parameters:\n",
    "    - tickers: List of stock tickers\n",
    "    - sector_map: Dictionary mapping tickers to sectors (to avoid re-fetching)\n",
    "    - lookback_years: Years of historical data to fetch\n",
    "    - min_daily_obs: Minimum daily observations required (default 40 out of 60)\n",
    "    \n",
    "    Returns:\n",
    "    - z_score_matrix: Wide format (Date x Ticker) of defensive Z-scores\n",
    "    - detailed_df: Long format with all intermediate calculations\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # 1. FETCH DAILY DATA\n",
    "    print(f\"\\nDownloading daily price data for {len(tickers)} tickers...\")\n",
    "    \n",
    "    try:\n",
    "        data = yf.download(\n",
    "            tickers,\n",
    "            period=f\"{lookback_years}y\",\n",
    "            interval=\"1d\",\n",
    "            progress=True,\n",
    "            auto_adjust=True,\n",
    "            threads=True\n",
    "        )\n",
    "        \n",
    "        # Extract Close prices\n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            if 'Close' in data.columns.get_level_values(0):\n",
    "                prices = data['Close']\n",
    "            else:\n",
    "                print(\"Error: Could not find 'Close' prices\")\n",
    "                return None, None\n",
    "        else:\n",
    "            if 'Close' in data.columns:\n",
    "                prices = data['Close']\n",
    "            else:\n",
    "                prices = data\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading data: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"Data shape: {prices.shape}\")\n",
    "    \n",
    "    # 2. CALCULATE DAILY LOG RETURNS\n",
    "    print(\"\\nCalculating daily log returns...\")\n",
    "    log_returns = np.log(prices / prices.shift(1))\n",
    "    \n",
    "    # 3. CALCULATE 60-DAY ROLLING VOLATILITY (ANNUALIZED)\n",
    "    print(\"Calculating 60-day rolling realized volatility...\")\n",
    "    window = 60\n",
    "    \n",
    "    # Rolling standard deviation of log returns\n",
    "    rolling_vol = log_returns.rolling(window=window, min_periods=min_daily_obs).std()\n",
    "    \n",
    "    # Annualize: multiply by sqrt(252 trading days)\n",
    "    annualized_vol = rolling_vol * np.sqrt(252)\n",
    "    \n",
    "    # 4. RESAMPLE TO MONTHLY (END OF MONTH)\n",
    "    print(\"Resampling to monthly frequency...\")\n",
    "    monthly_vol = annualized_vol.resample('M').last()\n",
    "    \n",
    "    # Drop tickers with insufficient data\n",
    "    monthly_vol = monthly_vol.dropna(axis=1, thresh=12)\n",
    "    valid_tickers = monthly_vol.columns.tolist()\n",
    "    \n",
    "    print(f\"Valid tickers with sufficient data: {len(valid_tickers)}\")\n",
    "    \n",
    "    if len(valid_tickers) == 0:\n",
    "        print(\"ERROR: No valid tickers with sufficient data!\")\n",
    "        return None, None\n",
    "    \n",
    "    # 5. INVERT VOLATILITY (LOWER VOL IS BETTER)\n",
    "    # Define x_low = -sigma\n",
    "    low_vol_signal = -monthly_vol\n",
    "    \n",
    "    # Drop rows with all NaN\n",
    "    low_vol_signal = low_vol_signal.dropna(how='all')\n",
    "    \n",
    "    # 6. PREPARE FOR CROSS-SECTIONAL STANDARDIZATION\n",
    "    # Convert to long format\n",
    "    df_long = low_vol_signal.stack().reset_index()\n",
    "    df_long.columns = ['Date', 'Ticker', 'Low_Vol_Raw']\n",
    "    \n",
    "    # Add original volatility for reference\n",
    "    vol_long = monthly_vol.stack().reset_index()\n",
    "    vol_long.columns = ['Date', 'Ticker', 'Realized_Vol']\n",
    "    df_long = df_long.merge(vol_long, on=['Date', 'Ticker'], how='left')\n",
    "    \n",
    "    # Map Sectors (reuse sector map from momentum calculation)\n",
    "    print(\"\\nMapping sectors from existing sector map...\")\n",
    "    df_long['Sector'] = df_long['Ticker'].map(sector_map)\n",
    "    \n",
    "    # 7. WINSORIZATION (Cross-sectional per Date)\n",
    "    print(\"Applying winsorization...\")\n",
    "    def winsorize_group(group):\n",
    "        lower = group.quantile(0.05)\n",
    "        upper = group.quantile(0.95)\n",
    "        return group.clip(lower, upper)\n",
    "    \n",
    "    df_long['Low_Vol_Winsorized'] = df_long.groupby('Date')['Low_Vol_Raw'] \\\n",
    "                                           .transform(winsorize_group)\n",
    "    \n",
    "    # 8. SECTOR Z-SCORES\n",
    "    print(\"Calculating sector-neutral Z-scores...\")\n",
    "    def calc_zscore(group):\n",
    "        if len(group) < 2:\n",
    "            return 0.0\n",
    "        sigma = group.std()\n",
    "        if sigma == 0:\n",
    "            return 0.0\n",
    "        return (group - group.mean()) / sigma\n",
    "    \n",
    "    df_long['Z_LowVol'] = df_long.groupby(['Date', 'Sector'])['Low_Vol_Winsorized'] \\\n",
    "                                 .transform(calc_zscore)\n",
    "    \n",
    "    # Pivot to wide format\n",
    "    final_factor = df_long.pivot(index='Date', columns='Ticker', values='Z_LowVol')\n",
    "    \n",
    "    return final_factor, df_long\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# Extract sector map from detailed_df to reuse it\n",
    "sector_map = detailed_df[['Ticker', 'Sector']].drop_duplicates().set_index('Ticker')['Sector'].to_dict()\n",
    "\n",
    "print(\"\\nRunning defensive factor calculation...\")\n",
    "lowvol_matrix, defensive_df = calculate_defensive_factor(ticker_list, sector_map)\n",
    "\n",
    "# Check if calculation was successful\n",
    "if lowvol_matrix is not None and not lowvol_matrix.empty:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CALCULATION SUCCESSFUL\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nData shape: {defensive_df.shape}\")\n",
    "    print(f\"Date range: {defensive_df['Date'].min()} to {defensive_df['Date'].max()}\")\n",
    "    print(f\"\\nMost Recent Low Volatility Z-Scores (Top 10):\")\n",
    "    latest_date = lowvol_matrix.index[-1]\n",
    "    print(lowvol_matrix.loc[latest_date].sort_values(ascending=False).head(10))\n",
    "else:\n",
    "    print(\"\\nCalculation failed. Please check the errors above and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21274c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEFENSIVE FACTOR - QUINTILE DISTRIBUTION\n",
      "======================================================================\n",
      "\n",
      "Quintile Distribution:\n",
      "Defensive_Quintile\n",
      "1    5912\n",
      "2    5853\n",
      "3    5855\n",
      "4    5876\n",
      "5    5857\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of data with quintiles:\n",
      "         Date Ticker  Realized_Vol  Z_LowVol Defensive_Quintile\n",
      "0  2021-01-31      A      0.212367  0.840904                  4\n",
      "1  2021-01-31   AAPL      0.319224 -0.123935                  2\n",
      "2  2021-01-31   ABBV      0.231352  0.540806                  4\n",
      "3  2021-01-31    ABT      0.194546  1.122615                  5\n",
      "4  2021-01-31   ACGL      0.318919 -0.454541                  2\n",
      "5  2021-01-31    ACN      0.245904  0.712566                  4\n",
      "6  2021-01-31   ADBE      0.241050  0.767944                  4\n",
      "7  2021-01-31    ADI      0.240189  0.777770                  4\n",
      "8  2021-01-31    ADM      0.259394 -0.336495                  2\n",
      "9  2021-01-31    ADP      0.183162  1.405449                  5\n",
      "10 2021-01-31   ADSK      0.316312 -0.090716                  3\n",
      "11 2021-01-31    AEE      0.209598  0.627986                  4\n",
      "12 2021-01-31    AEP      0.182199  1.103859                  5\n",
      "13 2021-01-31    AES      0.416265 -3.398510                  1\n",
      "14 2021-01-31    AFL      0.257070  0.523463                  4\n",
      "15 2021-01-31    AIG      0.306766 -0.262381                  2\n",
      "16 2021-01-31    AIZ      0.235786  0.860031                  5\n",
      "17 2021-01-31    AJG      0.209802  1.270901                  5\n",
      "18 2021-01-31   AKAM      0.285898  0.256280                  3\n",
      "19 2021-01-31    ALB      0.425254 -1.134950                  1\n"
     ]
    }
   ],
   "source": [
    "# Add defensive quintiles based on Z_LowVol scores\n",
    "defensive_df['Defensive_Quintile'] = defensive_df.groupby('Date')['Z_LowVol'].transform(\n",
    "    lambda x: pd.qcut(x, q=5, labels=[1, 2, 3, 4, 5], duplicates='drop')\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DEFENSIVE FACTOR - QUINTILE DISTRIBUTION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nQuintile Distribution:\")\n",
    "print(defensive_df['Defensive_Quintile'].value_counts().sort_index())\n",
    "print(f\"\\nSample of data with quintiles:\")\n",
    "print(defensive_df[['Date', 'Ticker', 'Realized_Vol', 'Z_LowVol', 'Defensive_Quintile']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21f21fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEFENSIVE FACTOR BACKTEST - Monthly Rebalancing\n",
      "======================================================================\n",
      "\n",
      "Aligning dates and merging forward returns from momentum calculation...\n",
      "\n",
      "Calculating quintile performance statistics...\n",
      "\n",
      "======================================================================\n",
      "Average Returns by Defensive Quintile (%):\n",
      "Quintile 5 = Lowest Volatility (Most Defensive)\n",
      "Quintile 1 = Highest Volatility (Least Defensive)\n",
      "======================================================================\n",
      "                    Mean_Monthly_Return  Median_Monthly_Return    Std_Dev  \\\n",
      "Defensive_Quintile                                                          \n",
      "1                              1.519653               0.650555  13.063994   \n",
      "2                              0.816959               0.565110   9.580971   \n",
      "3                              0.632097               0.634972   8.213939   \n",
      "4                              0.665756               0.458433   7.225978   \n",
      "5                              0.630516               0.586273   6.855563   \n",
      "\n",
      "                    Count  \n",
      "Defensive_Quintile         \n",
      "1                    4660  \n",
      "2                    4658  \n",
      "3                    4667  \n",
      "4                    4683  \n",
      "5                    4672  \n",
      "\n",
      "Defensive Spread (Low Vol - High Vol): -0.89% per month\n",
      "Annualized Spread: -10.67%\n",
      "\n",
      "Sharpe Ratios by Quintile (assuming 0% risk-free rate):\n",
      "Quintile 1: 0.403\n",
      "Quintile 2: 0.295\n",
      "Quintile 3: 0.267\n",
      "Quintile 4: 0.319\n",
      "Quintile 5: 0.319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tushar\\AppData\\Local\\Temp\\ipykernel_6524\\1394301052.py:33: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  quintile_stats = defensive_df.groupby('Defensive_Quintile')['Forward_Return'].agg([\n"
     ]
    }
   ],
   "source": [
    "# Calculate forward returns for defensive factor backtesting\n",
    "print(\"=\"*70)\n",
    "print(\"DEFENSIVE FACTOR BACKTEST - Monthly Rebalancing\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sort by Ticker and Date to ensure proper ordering\n",
    "defensive_df = defensive_df.sort_values(['Ticker', 'Date'])\n",
    "\n",
    "# Normalize dates to month-start for both dataframes to enable merging\n",
    "print(\"\\nAligning dates and merging forward returns from momentum calculation...\")\n",
    "\n",
    "# Convert defensive_df dates to period (month) then back to start of month\n",
    "defensive_df['Date_Month'] = pd.to_datetime(defensive_df['Date']).dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "# Extract returns from detailed_df with month-start dates (these are now proper 1-month returns)\n",
    "returns_from_momentum = detailed_df[['Date', 'Ticker', 'Forward_Return']].copy()\n",
    "\n",
    "# Merge on the normalized month date\n",
    "defensive_df = defensive_df.merge(\n",
    "    returns_from_momentum, \n",
    "    left_on=['Date_Month', 'Ticker'],\n",
    "    right_on=['Date', 'Ticker'],\n",
    "    how='left',\n",
    "    suffixes=('', '_mom')\n",
    ")\n",
    "\n",
    "# Drop the temporary columns and keep original Date from defensive_df\n",
    "defensive_df = defensive_df.drop(columns=['Date_mom', 'Date_Month'])\n",
    "\n",
    "# Calculate quintile statistics\n",
    "print(\"\\nCalculating quintile performance statistics...\")\n",
    "\n",
    "quintile_stats = defensive_df.groupby('Defensive_Quintile')['Forward_Return'].agg([\n",
    "    ('Mean_Monthly_Return', 'mean'),\n",
    "    ('Median_Monthly_Return', 'median'),\n",
    "    ('Std_Dev', 'std'),\n",
    "    ('Count', 'count')\n",
    "])\n",
    "\n",
    "# Convert to percentage\n",
    "quintile_stats['Mean_Monthly_Return'] = quintile_stats['Mean_Monthly_Return'] * 100\n",
    "quintile_stats['Median_Monthly_Return'] = quintile_stats['Median_Monthly_Return'] * 100\n",
    "quintile_stats['Std_Dev'] = quintile_stats['Std_Dev'] * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Average Returns by Defensive Quintile (%):\")\n",
    "print(\"Quintile 5 = Lowest Volatility (Most Defensive)\")\n",
    "print(\"Quintile 1 = Highest Volatility (Least Defensive)\")\n",
    "print(\"=\"*70)\n",
    "print(quintile_stats)\n",
    "\n",
    "# Calculate spread (Q5 - Q1)\n",
    "# For defensive, we expect Q5 (low vol) to have better risk-adjusted returns\n",
    "if 5 in quintile_stats.index and 1 in quintile_stats.index:\n",
    "    spread = quintile_stats.loc[5, 'Mean_Monthly_Return'] - quintile_stats.loc[1, 'Mean_Monthly_Return']\n",
    "    print(f\"\\nDefensive Spread (Low Vol - High Vol): {spread:.2f}% per month\")\n",
    "    print(f\"Annualized Spread: {spread * 12:.2f}%\")\n",
    "    \n",
    "    # Calculate Sharpe ratio for each quintile\n",
    "    print(\"\\nSharpe Ratios by Quintile (assuming 0% risk-free rate):\")\n",
    "    for q in range(1, 6):\n",
    "        if q in quintile_stats.index:\n",
    "            mean_ret = quintile_stats.loc[q, 'Mean_Monthly_Return']\n",
    "            std_ret = quintile_stats.loc[q, 'Std_Dev']\n",
    "            if std_ret > 0:\n",
    "                sharpe = (mean_ret / std_ret) * np.sqrt(12)  # Annualized\n",
    "                print(f\"Quintile {q}: {sharpe:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf5de4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "QUALITY & VALUE FACTORS - DATA PREPARATION\n",
      "======================================================================\n",
      "\n",
      "Loaded quality/value data:\n",
      "Shape: (23841, 4)\n",
      "Columns: ['Date', 'Ticker', 'EV/EBIT', 'ROIC']\n",
      "\n",
      "Sample data:\n",
      "        Date Ticker   EV/EBIT     ROIC\n",
      "0  12/1/2021      A   34.1652  12.3997\n",
      "1   1/1/2022      A  35.29233  12.3997\n",
      "2   2/1/2022      A  31.28716  12.4219\n",
      "3   3/1/2022      A  28.37417  12.4219\n",
      "4   4/1/2022      A  28.73438  12.4219\n",
      "\n",
      " Found EV/EBIT and ROIC columns\n"
     ]
    }
   ],
   "source": [
    "# Load quality/value data and prepare for analysis\n",
    "print(\"=\"*70)\n",
    "print(\"QUALITY & VALUE FACTORS - DATA PREPARATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load the quality/value CSV file\n",
    "quality_value_df = pd.read_csv('spx_quality_value.csv')\n",
    "\n",
    "# Replace \"/\" with \"-\" in ticker column to match our format\n",
    "quality_value_df['Ticker'] = quality_value_df['Ticker'].str.replace('/', '-')\n",
    "\n",
    "# Replace \"NM\" (Not Meaningful) with 999 for EV/EBIT to place in worst quintile\n",
    "if 'EV/EBIT' in quality_value_df.columns:\n",
    "    quality_value_df['EV/EBIT'] = quality_value_df['EV/EBIT'].replace('NM', '999')\n",
    "\n",
    "print(f\"\\nLoaded quality/value data:\")\n",
    "print(f\"Shape: {quality_value_df.shape}\")\n",
    "print(f\"Columns: {quality_value_df.columns.tolist()}\")\n",
    "print(f\"\\nSample data:\")\n",
    "print(quality_value_df.head())\n",
    "\n",
    "# Check for required columns\n",
    "if 'EV/EBIT' in quality_value_df.columns and 'ROIC' in quality_value_df.columns:\n",
    "    print(\"\\n Found EV/EBIT and ROIC columns\")\n",
    "else:\n",
    "    print(\"\\n Warning: Could not find expected columns\")\n",
    "    print(f\"Available columns: {quality_value_df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bafbdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MERGING QUALITY/VALUE WITH MOMENTUM DATA\n",
      "======================================================================\n",
      "\n",
      "Converted to numeric:\n",
      "EV/EBIT type: float64\n",
      "ROIC type: float64\n",
      "\n",
      "Found Date column in quality_value_df - merging on Ticker and Date\n",
      "\n",
      "======================================================================\n",
      "MERGING DEFENSIVE FACTOR DATA\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "CREATING VALUE AND QUALITY QUINTILES\n",
      "======================================================================\n",
      "\n",
      "Merged data shape: (23841, 15)\n",
      "Columns: ['Date', 'Ticker', 'Raw_Momentum', 'Sector', 'Mom_Winsorized', 'Z_Momentum', 'Momentum_Quintile', 'Forward_Return', 'EV/EBIT', 'ROIC', 'Realized_Vol', 'Z_LowVol', 'Defensive_Quintile', 'Value_Quintile', 'Quality_Quintile']\n",
      "\n",
      "Rows with EV/EBIT data: 23841\n",
      "Rows with ROIC data: 23815\n",
      "Rows with Z_LowVol data: 23841\n",
      "Rows with Defensive_Quintile data: 23841\n",
      "Rows with Value_Quintile data: 23841\n",
      "Rows with Quality_Quintile data: 23815\n",
      "Total rows: 23841\n",
      "\n",
      "Sample of merged data:\n",
      "         Date Ticker  Z_Momentum Momentum_Quintile  Z_LowVol  \\\n",
      "0  2021-12-01      A    0.476937                 4  0.508631   \n",
      "1  2021-12-01   AAPL   -0.522009                 2  0.987646   \n",
      "2  2021-12-01   ABBV   -0.553359                 2  1.214881   \n",
      "3  2021-12-01    ABT   -0.178019                 3  0.996389   \n",
      "4  2021-12-01   ACGL   -1.023025                 1  0.380416   \n",
      "5  2021-12-01    ACN    0.622715                 4  0.907111   \n",
      "6  2021-12-01   ADBE    0.232228                 4 -1.055102   \n",
      "7  2021-12-01    ADI   -0.247794                 3  0.839087   \n",
      "8  2021-12-01    ADM    1.399820                 5  0.185797   \n",
      "9  2021-12-01    ADP    0.227898                 3  1.582826   \n",
      "10 2021-12-01   ADSK   -0.949008                 2 -1.456907   \n",
      "11 2021-12-01    AEE    0.282467                 4  0.429401   \n",
      "12 2021-12-01    AEP   -0.432514                 2  0.668802   \n",
      "13 2021-12-01    AES    0.062704                 3 -0.988034   \n",
      "14 2021-12-01    AFL   -0.669961                 2  0.628227   \n",
      "15 2021-12-01    AIG    1.207860                 5 -0.300645   \n",
      "16 2021-12-01    AIZ   -0.817869                 2  1.238320   \n",
      "17 2021-12-01    AJG    0.061086                 3  1.310568   \n",
      "18 2021-12-01   AKAM   -1.111098                 1  1.164792   \n",
      "19 2021-12-01    ALB    1.439728                 5 -1.165496   \n",
      "\n",
      "   Defensive_Quintile   EV/EBIT Value_Quintile     ROIC Quality_Quintile  \n",
      "0                   4  34.16520              2  12.3997                4  \n",
      "1                   5  24.31677              3  41.4292                5  \n",
      "2                   5  13.50405              4  -1.5393                1  \n",
      "3                   5  26.34638              2   8.1381                3  \n",
      "4                   3   7.14122              5  12.4741                4  \n",
      "5                   5  29.30920              2  16.8952                5  \n",
      "6                   1  56.43885              1  32.8605                5  \n",
      "7                   5  48.38231              1   0.8951                2  \n",
      "8                   3  13.44369              4   5.8669                3  \n",
      "9                   5  27.88351              2  13.1215                4  \n",
      "10                  1  82.59264              1  40.6088                5  \n",
      "11                  3  23.21377              3   2.0330                2  \n",
      "12                  4  21.87558              3   1.5770                2  \n",
      "13                  1  14.40739              4   0.5472                2  \n",
      "14                  4   7.24945              5   7.8857                3  \n",
      "15                  2   9.26525              5   4.4638                3  \n",
      "16                  5   8.67284              5  15.2589                5  \n",
      "17                  5  26.51276              2   4.4745                3  \n",
      "18                  5  23.57538              3   8.4873                4  \n",
      "19                  1  51.34159              1   0.4836                2  \n"
     ]
    }
   ],
   "source": [
    "# Merge quality/value data with detailed_df (momentum data)\n",
    "print(\"=\"*70)\n",
    "print(\"MERGING QUALITY/VALUE WITH MOMENTUM DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Convert EV/EBIT and ROIC to numeric (handle any non-numeric values)\n",
    "quality_value_df['EV/EBIT'] = pd.to_numeric(quality_value_df['EV/EBIT'], errors='coerce')\n",
    "quality_value_df['ROIC'] = pd.to_numeric(quality_value_df['ROIC'], errors='coerce')\n",
    "\n",
    "print(f\"\\nConverted to numeric:\")\n",
    "print(f\"EV/EBIT type: {quality_value_df['EV/EBIT'].dtype}\")\n",
    "print(f\"ROIC type: {quality_value_df['ROIC'].dtype}\")\n",
    "\n",
    "# Check if quality_value_df has a Date column\n",
    "if 'Date' in quality_value_df.columns:\n",
    "    print(\"\\nFound Date column in quality_value_df - merging on Ticker and Date\")\n",
    "    # Convert date to datetime for proper matching\n",
    "    quality_value_df['Date'] = pd.to_datetime(quality_value_df['Date'])\n",
    "    detailed_df['Date'] = pd.to_datetime(detailed_df['Date'])\n",
    "    \n",
    "    # Merge on both Ticker and Date\n",
    "    merged_df = detailed_df.merge(\n",
    "        quality_value_df[['Date', 'Ticker', 'EV/EBIT', 'ROIC']], \n",
    "        on=['Ticker', 'Date'], \n",
    "        how='left'\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nNo Date column in quality_value_df - treating as static data\")\n",
    "    print(\"Broadcasting quality/value metrics across all dates for each ticker\")\n",
    "    # Merge on Ticker only (broadcasts static values across all dates)\n",
    "    merged_df = detailed_df.merge(\n",
    "        quality_value_df[['Ticker', 'EV/EBIT', 'ROIC']], \n",
    "        on='Ticker', \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# Now merge with defensive factor data\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MERGING DEFENSIVE FACTOR DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Normalize dates for both dataframes to enable proper merging\n",
    "merged_df['Date'] = pd.to_datetime(merged_df['Date'])\n",
    "defensive_df['Date'] = pd.to_datetime(defensive_df['Date'])\n",
    "\n",
    "# Create normalized month column for matching\n",
    "merged_df['Date_Month'] = merged_df['Date'].dt.to_period('M').dt.to_timestamp()\n",
    "defensive_df['Date_Month'] = defensive_df['Date'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "# Select defensive columns to merge\n",
    "defensive_cols = ['Date_Month', 'Ticker', 'Realized_Vol', 'Z_LowVol', 'Defensive_Quintile']\n",
    "\n",
    "# Merge defensive data\n",
    "merged_df = merged_df.merge(\n",
    "    defensive_df[defensive_cols],\n",
    "    left_on=['Date_Month', 'Ticker'],\n",
    "    right_on=['Date_Month', 'Ticker'],\n",
    "    how='left',\n",
    "    suffixes=('', '_def')\n",
    ")\n",
    "\n",
    "# Drop the temporary Date_Month column\n",
    "merged_df = merged_df.drop(columns=['Date_Month'])\n",
    "\n",
    "# Create Value and Quality quintiles\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING VALUE AND QUALITY QUINTILES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Value Quintile (EV/EBIT): Lower is better, so invert with -EV/EBIT\n",
    "merged_df['Value_Quintile'] = merged_df.groupby('Date')['EV/EBIT'].transform(\n",
    "    lambda x: pd.qcut(-x, q=5, labels=[1, 2, 3, 4, 5], duplicates='drop') if x.notna().sum() >= 5 else np.nan\n",
    ")\n",
    "\n",
    "# Quality Quintile (ROIC): Higher is better\n",
    "merged_df['Quality_Quintile'] = merged_df.groupby('Date')['ROIC'].transform(\n",
    "    lambda x: pd.qcut(x, q=5, labels=[1, 2, 3, 4, 5], duplicates='drop') if x.notna().sum() >= 5 else np.nan\n",
    ")\n",
    "\n",
    "print(f\"\\nMerged data shape: {merged_df.shape}\")\n",
    "print(f\"Columns: {merged_df.columns.tolist()}\")\n",
    "\n",
    "# Check merge success\n",
    "print(f\"\\nRows with EV/EBIT data: {merged_df['EV/EBIT'].notna().sum()}\")\n",
    "print(f\"Rows with ROIC data: {merged_df['ROIC'].notna().sum()}\")\n",
    "print(f\"Rows with Z_LowVol data: {merged_df['Z_LowVol'].notna().sum()}\")\n",
    "print(f\"Rows with Defensive_Quintile data: {merged_df['Defensive_Quintile'].notna().sum()}\")\n",
    "print(f\"Rows with Value_Quintile data: {merged_df['Value_Quintile'].notna().sum()}\")\n",
    "print(f\"Rows with Quality_Quintile data: {merged_df['Quality_Quintile'].notna().sum()}\")\n",
    "print(f\"Total rows: {len(merged_df)}\")\n",
    "print(f\"\\nSample of merged data:\")\n",
    "print(merged_df[['Date', 'Ticker', 'Z_Momentum', 'Momentum_Quintile',\n",
    "                 'Z_LowVol', 'Defensive_Quintile',\n",
    "                 'EV/EBIT', 'Value_Quintile',\n",
    "                 'ROIC', 'Quality_Quintile']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92afd146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VALUE FACTOR BACKTEST (EV/EBIT)\n",
      "======================================================================\n",
      "\n",
      "Value Quintile Distribution:\n",
      "Value_Quintile\n",
      "1    4793\n",
      "2    4760\n",
      "3    4756\n",
      "4    4760\n",
      "5    4772\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data:\n",
      "         Date Ticker   EV/EBIT Value_Quintile\n",
      "0  2021-12-01      A  34.16520              2\n",
      "1  2021-12-01   AAPL  24.31677              3\n",
      "2  2021-12-01   ABBV  13.50405              4\n",
      "3  2021-12-01    ABT  26.34638              2\n",
      "4  2021-12-01   ACGL   7.14122              5\n",
      "5  2021-12-01    ACN  29.30920              2\n",
      "6  2021-12-01   ADBE  56.43885              1\n",
      "7  2021-12-01    ADI  48.38231              1\n",
      "8  2021-12-01    ADM  13.44369              4\n",
      "9  2021-12-01    ADP  27.88351              2\n",
      "10 2021-12-01   ADSK  82.59264              1\n",
      "11 2021-12-01    AEE  23.21377              3\n",
      "12 2021-12-01    AEP  21.87558              3\n",
      "13 2021-12-01    AES  14.40739              4\n",
      "14 2021-12-01    AFL   7.24945              5\n",
      "15 2021-12-01    AIG   9.26525              5\n",
      "16 2021-12-01    AIZ   8.67284              5\n",
      "17 2021-12-01    AJG  26.51276              2\n",
      "18 2021-12-01   AKAM  23.57538              3\n",
      "19 2021-12-01    ALB  51.34159              1\n",
      "\n",
      "======================================================================\n",
      "VALUE STRATEGY BACKTEST\n",
      "======================================================================\n",
      "\n",
      "Average Returns by Value Quintile (%):\n",
      "Quintile 5 = Lowest EV/EBIT (Best Value)\n",
      "Quintile 1 = Highest EV/EBIT (Worst Value)\n",
      "======================================================================\n",
      "                Mean_Monthly_Return  Median_Monthly_Return    Std_Dev  Count\n",
      "Value_Quintile                                                              \n",
      "1                          0.659846               0.190107  11.189832   4692\n",
      "2                          0.502194               0.345478   8.192327   4660\n",
      "3                          0.809177               0.727103   8.019049   4656\n",
      "4                          1.092574               0.695903   8.954784   4660\n",
      "5                          1.199772               0.947587   9.589760   4672\n",
      "\n",
      "Value Spread (Q5 - Q1): 0.54% per month\n",
      "Annualized Spread: 6.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tushar\\AppData\\Local\\Temp\\ipykernel_6524\\2457916920.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  value_stats = merged_df.groupby('Value_Quintile')['Forward_Return'].agg([\n"
     ]
    }
   ],
   "source": [
    "# Backtest Value factor (already created in merged_df)\n",
    "print(\"=\"*70)\n",
    "print(\"VALUE FACTOR BACKTEST (EV/EBIT)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nValue Quintile Distribution:\")\n",
    "print(merged_df['Value_Quintile'].value_counts().sort_index())\n",
    "print(f\"\\nSample data:\")\n",
    "print(merged_df[['Date', 'Ticker', 'EV/EBIT', 'Value_Quintile']].dropna().head(20))\n",
    "\n",
    "# Calculate forward returns by Value quintile\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALUE STRATEGY BACKTEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "value_stats = merged_df.groupby('Value_Quintile')['Forward_Return'].agg([\n",
    "    ('Mean_Monthly_Return', 'mean'),\n",
    "    ('Median_Monthly_Return', 'median'),\n",
    "    ('Std_Dev', 'std'),\n",
    "    ('Count', 'count')\n",
    "])\n",
    "\n",
    "# Convert to percentage\n",
    "value_stats['Mean_Monthly_Return'] = value_stats['Mean_Monthly_Return'] * 100\n",
    "value_stats['Median_Monthly_Return'] = value_stats['Median_Monthly_Return'] * 100\n",
    "value_stats['Std_Dev'] = value_stats['Std_Dev'] * 100\n",
    "\n",
    "print(\"\\nAverage Returns by Value Quintile (%):\")\n",
    "print(\"Quintile 5 = Lowest EV/EBIT (Best Value)\")\n",
    "print(\"Quintile 1 = Highest EV/EBIT (Worst Value)\")\n",
    "print(\"=\"*70)\n",
    "print(value_stats)\n",
    "\n",
    "# Calculate spread\n",
    "if 5 in value_stats.index and 1 in value_stats.index:\n",
    "    spread = value_stats.loc[5, 'Mean_Monthly_Return'] - value_stats.loc[1, 'Mean_Monthly_Return']\n",
    "    print(f\"\\nValue Spread (Q5 - Q1): {spread:.2f}% per month\")\n",
    "    print(f\"Annualized Spread: {spread * 12:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd0641dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Mean_Monthly_Return  Median_Monthly_Return    Std_Dev  Count\n",
      "Value_Quintile                                                              \n",
      "1                          0.659846               0.190107  11.189832   4692\n",
      "2                          0.502194               0.345478   8.192327   4660\n",
      "3                          0.809177               0.727103   8.019049   4656\n",
      "4                          1.092574               0.695903   8.954784   4660\n",
      "5                          1.199772               0.947587   9.589760   4672\n"
     ]
    }
   ],
   "source": [
    "print(value_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb930ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "QUALITY FACTOR BACKTEST (ROIC)\n",
      "======================================================================\n",
      "\n",
      "Quality Quintile Distribution:\n",
      "Quality_Quintile\n",
      "1    4826\n",
      "2    4711\n",
      "3    4756\n",
      "4    4755\n",
      "5    4767\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data:\n",
      "         Date Ticker     ROIC Quality_Quintile\n",
      "0  2021-12-01      A  12.3997                4\n",
      "1  2021-12-01   AAPL  41.4292                5\n",
      "2  2021-12-01   ABBV  -1.5393                1\n",
      "3  2021-12-01    ABT   8.1381                3\n",
      "4  2021-12-01   ACGL  12.4741                4\n",
      "5  2021-12-01    ACN  16.8952                5\n",
      "6  2021-12-01   ADBE  32.8605                5\n",
      "7  2021-12-01    ADI   0.8951                2\n",
      "8  2021-12-01    ADM   5.8669                3\n",
      "9  2021-12-01    ADP  13.1215                4\n",
      "10 2021-12-01   ADSK  40.6088                5\n",
      "11 2021-12-01    AEE   2.0330                2\n",
      "12 2021-12-01    AEP   1.5770                2\n",
      "13 2021-12-01    AES   0.5472                2\n",
      "14 2021-12-01    AFL   7.8857                3\n",
      "15 2021-12-01    AIG   4.4638                3\n",
      "16 2021-12-01    AIZ  15.2589                5\n",
      "17 2021-12-01    AJG   4.4745                3\n",
      "18 2021-12-01   AKAM   8.4873                4\n",
      "19 2021-12-01    ALB   0.4836                2\n",
      "\n",
      "======================================================================\n",
      "QUALITY STRATEGY BACKTEST\n",
      "======================================================================\n",
      "\n",
      "Average Returns by Quality Quintile (%):\n",
      "Quintile 5 = Highest ROIC (Best Quality)\n",
      "Quintile 1 = Lowest ROIC (Worst Quality)\n",
      "======================================================================\n",
      "                  Mean_Monthly_Return  Median_Monthly_Return    Std_Dev  Count\n",
      "Quality_Quintile                                                              \n",
      "1                            1.017756               0.769153   9.933593   4726\n",
      "2                            0.588456               0.507540   7.865599   4611\n",
      "3                            0.793463               0.408036   8.713573   4656\n",
      "4                            0.859399               0.551244   9.255428   4655\n",
      "5                            0.992833               0.673973  10.338437   4667\n",
      "\n",
      "Quality Spread (Q5 - Q1): -0.02% per month\n",
      "Annualized Spread: -0.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tushar\\AppData\\Local\\Temp\\ipykernel_6524\\3224733538.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  quality_stats = merged_df.groupby('Quality_Quintile')['Forward_Return'].agg([\n"
     ]
    }
   ],
   "source": [
    "# Backtest Quality factor (already created in merged_df)\n",
    "print(\"=\"*70)\n",
    "print(\"QUALITY FACTOR BACKTEST (ROIC)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nQuality Quintile Distribution:\")\n",
    "print(merged_df['Quality_Quintile'].value_counts().sort_index())\n",
    "print(f\"\\nSample data:\")\n",
    "print(merged_df[['Date', 'Ticker', 'ROIC', 'Quality_Quintile']].dropna().head(20))\n",
    "\n",
    "# Calculate forward returns by Quality quintile\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"QUALITY STRATEGY BACKTEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "quality_stats = merged_df.groupby('Quality_Quintile')['Forward_Return'].agg([\n",
    "    ('Mean_Monthly_Return', 'mean'),\n",
    "    ('Median_Monthly_Return', 'median'),\n",
    "    ('Std_Dev', 'std'),\n",
    "    ('Count', 'count')\n",
    "])\n",
    "\n",
    "# Convert to percentage\n",
    "quality_stats['Mean_Monthly_Return'] = quality_stats['Mean_Monthly_Return'] * 100\n",
    "quality_stats['Median_Monthly_Return'] = quality_stats['Median_Monthly_Return'] * 100\n",
    "quality_stats['Std_Dev'] = quality_stats['Std_Dev'] * 100\n",
    "\n",
    "print(\"\\nAverage Returns by Quality Quintile (%):\")\n",
    "print(\"Quintile 5 = Highest ROIC (Best Quality)\")\n",
    "print(\"Quintile 1 = Lowest ROIC (Worst Quality)\")\n",
    "print(\"=\"*70)\n",
    "print(quality_stats)\n",
    "\n",
    "# Calculate spread\n",
    "if 5 in quality_stats.index and 1 in quality_stats.index:\n",
    "    spread = quality_stats.loc[5, 'Mean_Monthly_Return'] - quality_stats.loc[1, 'Mean_Monthly_Return']\n",
    "    print(f\"\\nQuality Spread (Q5 - Q1): {spread:.2f}% per month\")\n",
    "    print(f\"Annualized Spread: {spread * 12:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c101cc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Mean_Monthly_Return  Median_Monthly_Return    Std_Dev  Count\n",
      "Quality_Quintile                                                              \n",
      "1                            1.017756               0.769153   9.933593   4726\n",
      "2                            0.588456               0.507540   7.865599   4611\n",
      "3                            0.793463               0.408036   8.713573   4656\n",
      "4                            0.859399               0.551244   9.255428   4655\n",
      "5                            0.992833               0.673973  10.338437   4667\n"
     ]
    }
   ],
   "source": [
    "print(quality_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5559c8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Data saved to 'spx_all_factors_detailed.csv'\n",
      "======================================================================\n",
      "\n",
      "Columns in merged_df:\n",
      "['Date', 'Ticker', 'Raw_Momentum', 'Sector', 'Mom_Winsorized', 'Z_Momentum', 'Momentum_Quintile', 'Forward_Return', 'EV/EBIT', 'ROIC', 'Realized_Vol', 'Z_LowVol', 'Defensive_Quintile', 'Value_Quintile', 'Quality_Quintile']\n",
      "\n",
      "Total rows: 23841\n",
      "Date range: 2021-12-01 00:00:00 to 2025-11-01 00:00:00\n",
      "Number of unique tickers: 501\n",
      "\n",
      "======================================================================\n",
      "SUMMARY - ALL FACTORS\n",
      "======================================================================\n",
      "\n",
      "Momentum quintiles: 23841 observations\n",
      "Defensive quintiles: 23841 observations\n",
      "Value quintiles: 23841 observations\n",
      "Quality quintiles: 23815 observations\n",
      "\n",
      "======================================================================\n",
      "SAMPLE DATA - ALL FACTORS\n",
      "======================================================================\n",
      "         Date Ticker  Z_Momentum Momentum_Quintile  Z_LowVol  \\\n",
      "0  2021-12-01      A    0.476937                 4  0.508631   \n",
      "1  2021-12-01   AAPL   -0.522009                 2  0.987646   \n",
      "2  2021-12-01   ABBV   -0.553359                 2  1.214881   \n",
      "3  2021-12-01    ABT   -0.178019                 3  0.996389   \n",
      "4  2021-12-01   ACGL   -1.023025                 1  0.380416   \n",
      "5  2021-12-01    ACN    0.622715                 4  0.907111   \n",
      "6  2021-12-01   ADBE    0.232228                 4 -1.055102   \n",
      "7  2021-12-01    ADI   -0.247794                 3  0.839087   \n",
      "8  2021-12-01    ADM    1.399820                 5  0.185797   \n",
      "9  2021-12-01    ADP    0.227898                 3  1.582826   \n",
      "10 2021-12-01   ADSK   -0.949008                 2 -1.456907   \n",
      "11 2021-12-01    AEE    0.282467                 4  0.429401   \n",
      "12 2021-12-01    AEP   -0.432514                 2  0.668802   \n",
      "13 2021-12-01    AES    0.062704                 3 -0.988034   \n",
      "14 2021-12-01    AFL   -0.669961                 2  0.628227   \n",
      "15 2021-12-01    AIG    1.207860                 5 -0.300645   \n",
      "16 2021-12-01    AIZ   -0.817869                 2  1.238320   \n",
      "17 2021-12-01    AJG    0.061086                 3  1.310568   \n",
      "18 2021-12-01   AKAM   -1.111098                 1  1.164792   \n",
      "19 2021-12-01    ALB    1.439728                 5 -1.165496   \n",
      "\n",
      "   Defensive_Quintile   EV/EBIT Value_Quintile     ROIC Quality_Quintile  \\\n",
      "0                   4  34.16520              2  12.3997                4   \n",
      "1                   5  24.31677              3  41.4292                5   \n",
      "2                   5  13.50405              4  -1.5393                1   \n",
      "3                   5  26.34638              2   8.1381                3   \n",
      "4                   3   7.14122              5  12.4741                4   \n",
      "5                   5  29.30920              2  16.8952                5   \n",
      "6                   1  56.43885              1  32.8605                5   \n",
      "7                   5  48.38231              1   0.8951                2   \n",
      "8                   3  13.44369              4   5.8669                3   \n",
      "9                   5  27.88351              2  13.1215                4   \n",
      "10                  1  82.59264              1  40.6088                5   \n",
      "11                  3  23.21377              3   2.0330                2   \n",
      "12                  4  21.87558              3   1.5770                2   \n",
      "13                  1  14.40739              4   0.5472                2   \n",
      "14                  4   7.24945              5   7.8857                3   \n",
      "15                  2   9.26525              5   4.4638                3   \n",
      "16                  5   8.67284              5  15.2589                5   \n",
      "17                  5  26.51276              2   4.4745                3   \n",
      "18                  5  23.57538              3   8.4873                4   \n",
      "19                  1  51.34159              1   0.4836                2   \n",
      "\n",
      "    Forward_Return  \n",
      "0        -0.127341  \n",
      "1        -0.015712  \n",
      "2         0.011005  \n",
      "3        -0.094359  \n",
      "4         0.042070  \n",
      "5        -0.147075  \n",
      "6        -0.057772  \n",
      "7        -0.063560  \n",
      "8         0.109632  \n",
      "9        -0.160154  \n",
      "10       -0.111668  \n",
      "11        0.003388  \n",
      "12        0.016073  \n",
      "13       -0.087243  \n",
      "14        0.075869  \n",
      "15        0.021633  \n",
      "16       -0.021494  \n",
      "17       -0.066374  \n",
      "18       -0.021275  \n",
      "19       -0.054200  \n"
     ]
    }
   ],
   "source": [
    "# Save merged data with all factors\n",
    "merged_df.to_csv('spx_all_factors_detailed.csv', index=False)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Data saved to 'spx_all_factors_detailed.csv'\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nColumns in merged_df:\")\n",
    "print(merged_df.columns.tolist())\n",
    "print(f\"\\nTotal rows: {len(merged_df)}\")\n",
    "print(f\"Date range: {merged_df['Date'].min()} to {merged_df['Date'].max()}\")\n",
    "print(f\"Number of unique tickers: {merged_df['Ticker'].nunique()}\")\n",
    "\n",
    "# Summary of all factor quintiles\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY - ALL FACTORS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nMomentum quintiles: {merged_df['Momentum_Quintile'].notna().sum()} observations\")\n",
    "print(f\"Defensive quintiles: {merged_df['Defensive_Quintile'].notna().sum()} observations\")\n",
    "print(f\"Value quintiles: {merged_df['Value_Quintile'].notna().sum()} observations\")\n",
    "print(f\"Quality quintiles: {merged_df['Quality_Quintile'].notna().sum()} observations\")\n",
    "\n",
    "# Display sample with all factor scores\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE DATA - ALL FACTORS\")\n",
    "print(\"=\"*70)\n",
    "print(merged_df[['Date', 'Ticker', 'Z_Momentum', 'Momentum_Quintile', \n",
    "                 'Z_LowVol', 'Defensive_Quintile', \n",
    "                 'EV/EBIT', 'Value_Quintile',\n",
    "                 'ROIC', 'Quality_Quintile', 'Forward_Return']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3076a7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPOSITE MULTI-FACTOR SCORE\n",
      "======================================================================\n",
      "\n",
      "Total observations with at least 3 factors: 23841\n",
      "\n",
      "Composite Score Statistics:\n",
      "count    23841.000000\n",
      "mean        11.991821\n",
      "std          3.062269\n",
      "min          4.000000\n",
      "25%         10.000000\n",
      "50%         12.000000\n",
      "75%         14.000000\n",
      "max         20.000000\n",
      "Name: Composite_Score, dtype: float64\n",
      "\n",
      "Composite Quintile Distribution:\n",
      "Composite_Quintile\n",
      "1    5950\n",
      "2    5094\n",
      "3    4944\n",
      "4    4066\n",
      "5    3787\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "COMPOSITE STRATEGY BACKTEST\n",
      "======================================================================\n",
      "\n",
      "Average Returns by Composite Quintile (%):\n",
      "Quintile 5 = Highest Combined Score (Best)\n",
      "Quintile 1 = Lowest Combined Score (Worst)\n",
      "======================================================================\n",
      "                    Mean_Monthly_Return  Median_Monthly_Return    Std_Dev  \\\n",
      "Composite_Quintile                                                          \n",
      "1                              0.898727               0.574201  10.668161   \n",
      "2                              0.641633               0.395654   9.473097   \n",
      "3                              0.804632               0.562231   8.671852   \n",
      "4                              0.943100               0.479104   8.251885   \n",
      "5                              1.029096               0.893421   8.374428   \n",
      "\n",
      "                    Count  \n",
      "Composite_Quintile         \n",
      "1                    5802  \n",
      "2                    4957  \n",
      "3                    4894  \n",
      "4                    3989  \n",
      "5                    3698  \n",
      "\n",
      "Composite Spread (Q5 - Q1): 0.13% per month\n",
      "Annualized Spread: 1.56%\n",
      "\n",
      "Sharpe Ratios by Composite Quintile (assuming 0% risk-free rate):\n",
      "Quintile 1: 0.292\n",
      "Quintile 2: 0.235\n",
      "Quintile 3: 0.321\n",
      "Quintile 4: 0.396\n",
      "Quintile 5: 0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tushar\\AppData\\Local\\Temp\\ipykernel_6524\\670628016.py:42: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  composite_stats = composite_df.groupby('Composite_Quintile')['Forward_Return'].agg([\n"
     ]
    }
   ],
   "source": [
    "# Create composite score by summing all four quintile scores\n",
    "print(\"=\"*70)\n",
    "print(\"COMPOSITE MULTI-FACTOR SCORE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Convert quintiles to numeric first, then sum (higher is better for all)\n",
    "merged_df['Composite_Score'] = (\n",
    "    pd.to_numeric(merged_df['Momentum_Quintile'], errors='coerce').fillna(0) +\n",
    "    pd.to_numeric(merged_df['Defensive_Quintile'], errors='coerce').fillna(0) +\n",
    "    pd.to_numeric(merged_df['Value_Quintile'], errors='coerce').fillna(0) +\n",
    "    pd.to_numeric(merged_df['Quality_Quintile'], errors='coerce').fillna(0)\n",
    ")\n",
    "\n",
    "# Only keep rows where we have at least 3 out of 4 factors\n",
    "merged_df['Factor_Count'] = (\n",
    "    merged_df['Momentum_Quintile'].notna().astype(int) +\n",
    "    merged_df['Defensive_Quintile'].notna().astype(int) +\n",
    "    merged_df['Value_Quintile'].notna().astype(int) +\n",
    "    merged_df['Quality_Quintile'].notna().astype(int)\n",
    ")\n",
    "\n",
    "# Filter to rows with at least 3 factors\n",
    "composite_df = merged_df[merged_df['Factor_Count'] >= 3].copy()\n",
    "\n",
    "print(f\"\\nTotal observations with at least 3 factors: {len(composite_df)}\")\n",
    "print(f\"\\nComposite Score Statistics:\")\n",
    "print(composite_df['Composite_Score'].describe())\n",
    "\n",
    "# Create composite quintiles\n",
    "composite_df['Composite_Quintile'] = composite_df.groupby('Date')['Composite_Score'].transform(\n",
    "    lambda x: pd.qcut(x, q=5, labels=[1, 2, 3, 4, 5], duplicates='drop') if len(x) >= 5 else np.nan\n",
    ")\n",
    "\n",
    "print(f\"\\nComposite Quintile Distribution:\")\n",
    "print(composite_df['Composite_Quintile'].value_counts().sort_index())\n",
    "\n",
    "# Calculate backtest statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPOSITE STRATEGY BACKTEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "composite_stats = composite_df.groupby('Composite_Quintile')['Forward_Return'].agg([\n",
    "    ('Mean_Monthly_Return', 'mean'),\n",
    "    ('Median_Monthly_Return', 'median'),\n",
    "    ('Std_Dev', 'std'),\n",
    "    ('Count', 'count')\n",
    "])\n",
    "\n",
    "# Convert to percentage\n",
    "composite_stats['Mean_Monthly_Return'] = composite_stats['Mean_Monthly_Return'] * 100\n",
    "composite_stats['Median_Monthly_Return'] = composite_stats['Median_Monthly_Return'] * 100\n",
    "composite_stats['Std_Dev'] = composite_stats['Std_Dev'] * 100\n",
    "\n",
    "print(\"\\nAverage Returns by Composite Quintile (%):\")\n",
    "print(\"Quintile 5 = Highest Combined Score (Best)\")\n",
    "print(\"Quintile 1 = Lowest Combined Score (Worst)\")\n",
    "print(\"=\"*70)\n",
    "print(composite_stats)\n",
    "\n",
    "# Calculate spread\n",
    "if 5 in composite_stats.index and 1 in composite_stats.index:\n",
    "    spread = composite_stats.loc[5, 'Mean_Monthly_Return'] - composite_stats.loc[1, 'Mean_Monthly_Return']\n",
    "    print(f\"\\nComposite Spread (Q5 - Q1): {spread:.2f}% per month\")\n",
    "    print(f\"Annualized Spread: {spread * 12:.2f}%\")\n",
    "    \n",
    "    # Calculate Sharpe ratio\n",
    "    print(\"\\nSharpe Ratios by Composite Quintile (assuming 0% risk-free rate):\")\n",
    "    for q in range(1, 6):\n",
    "        if q in composite_stats.index:\n",
    "            mean_ret = composite_stats.loc[q, 'Mean_Monthly_Return']\n",
    "            std_ret = composite_stats.loc[q, 'Std_Dev']\n",
    "            if std_ret > 0:\n",
    "                sharpe = (mean_ret / std_ret) * np.sqrt(12)\n",
    "                print(f\"Quintile {q}: {sharpe:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6ff1fbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Create visualization of returns by composite quintile\u001b[39;00m\n\u001b[32m      4\u001b[39m fig, axes = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m14\u001b[39m, \u001b[32m10\u001b[39m))\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create visualization of returns by composite quintile\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Bar chart of mean returns by quintile\n",
    "ax1 = axes[0, 0]\n",
    "composite_stats['Mean_Monthly_Return'].plot(kind='bar', ax=ax1, color='steelblue', alpha=0.7)\n",
    "ax1.set_title('Average Monthly Return by Composite Quintile', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Composite Quintile', fontsize=10)\n",
    "ax1.set_ylabel('Mean Monthly Return (%)', fontsize=10)\n",
    "ax1.axhline(y=0, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=0)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(composite_stats['Mean_Monthly_Return']):\n",
    "    ax1.text(i, v + 0.05 if v > 0 else v - 0.05, f'{v:.2f}%', \n",
    "             ha='center', va='bottom' if v > 0 else 'top', fontsize=9)\n",
    "\n",
    "# 2. Box plot of return distribution by quintile\n",
    "ax2 = axes[0, 1]\n",
    "composite_df.boxplot(column='Forward_Return', by='Composite_Quintile', ax=ax2)\n",
    "ax2.set_title('Return Distribution by Composite Quintile', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Composite Quintile', fontsize=10)\n",
    "ax2.set_ylabel('Forward Return', fontsize=10)\n",
    "ax2.axhline(y=0, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "plt.sca(ax2)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# 3. Cumulative returns over time\n",
    "ax3 = axes[1, 0]\n",
    "for q in range(1, 6):\n",
    "    if q in composite_df['Composite_Quintile'].values:\n",
    "        quintile_data = composite_df[composite_df['Composite_Quintile'] == q].copy()\n",
    "        monthly_returns = quintile_data.groupby('Date')['Forward_Return'].mean()\n",
    "        cumulative_returns = (1 + monthly_returns).cumprod() - 1\n",
    "        ax3.plot(cumulative_returns.index, cumulative_returns.values * 100, \n",
    "                label=f'Q{q}', linewidth=2, alpha=0.8)\n",
    "\n",
    "ax3.set_title('Cumulative Returns by Composite Quintile', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Date', fontsize=10)\n",
    "ax3.set_ylabel('Cumulative Return (%)', fontsize=10)\n",
    "ax3.legend(loc='best', fontsize=9)\n",
    "ax3.grid(alpha=0.3)\n",
    "ax3.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# 4. Risk vs Return scatter\n",
    "ax4 = axes[1, 1]\n",
    "scatter = ax4.scatter(composite_stats['Std_Dev'], \n",
    "                     composite_stats['Mean_Monthly_Return'],\n",
    "                     s=200, c=range(1, len(composite_stats)+1), \n",
    "                     cmap='RdYlGn', alpha=0.7, edgecolors='black', linewidth=1.5)\n",
    "\n",
    "# Add labels for each quintile\n",
    "for idx, row in composite_stats.iterrows():\n",
    "    ax4.annotate(f'Q{int(idx)}', \n",
    "                (row['Std_Dev'], row['Mean_Monthly_Return']),\n",
    "                ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax4.set_title('Risk-Return Profile by Composite Quintile', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Standard Deviation (%)', fontsize=10)\n",
    "ax4.set_ylabel('Mean Monthly Return (%)', fontsize=10)\n",
    "ax4.grid(alpha=0.3)\n",
    "ax4.axhline(y=0, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VISUALIZATION COMPLETE\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('spx_signal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483da237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
